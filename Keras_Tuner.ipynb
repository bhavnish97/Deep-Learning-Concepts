{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VaL0eo_-CnKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ca2e58-6de6-45b5-c024-968e43fb9361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.49.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.1)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyGr556sC6gY",
        "outputId": "29fa7a2f-031c-4c79-e4a1-764ba1953b63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PqoV-1p0CqKZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"diabetes.csv\")"
      ],
      "metadata": {
        "id": "CthHR6itCqMb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PmS5pWSGCqOP",
        "outputId": "bd654bea-0e13-4f31-95c1-a06dc99f61a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5614aefd-027f-4b81-bb9c-211c94caceda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5614aefd-027f-4b81-bb9c-211c94caceda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5614aefd-027f-4b81-bb9c-211c94caceda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5614aefd-027f-4b81-bb9c-211c94caceda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "VnkdgKQVCqQM",
        "outputId": "0ccf15d5-7c3e-469d-edaa-eb4c21a466fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
              "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
              "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
              "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
              "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
              "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
              "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
              "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
              "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
              "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
              "\n",
              "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
              "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
              "Glucose                   0.331357  0.221071                  0.137337   \n",
              "BloodPressure             0.088933  0.281805                  0.041265   \n",
              "SkinThickness             0.436783  0.392573                  0.183928   \n",
              "Insulin                   1.000000  0.197859                  0.185071   \n",
              "BMI                       0.197859  1.000000                  0.140647   \n",
              "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
              "Age                      -0.042163  0.036242                  0.033561   \n",
              "Outcome                   0.130548  0.292695                  0.173844   \n",
              "\n",
              "                               Age   Outcome  \n",
              "Pregnancies               0.544341  0.221898  \n",
              "Glucose                   0.263514  0.466581  \n",
              "BloodPressure             0.239528  0.065068  \n",
              "SkinThickness            -0.113970  0.074752  \n",
              "Insulin                  -0.042163  0.130548  \n",
              "BMI                       0.036242  0.292695  \n",
              "DiabetesPedigreeFunction  0.033561  0.173844  \n",
              "Age                       1.000000  0.238356  \n",
              "Outcome                   0.238356  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0818dbd3-d102-48aa-a03b-101ca8933a0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129459</td>\n",
              "      <td>0.141282</td>\n",
              "      <td>-0.081672</td>\n",
              "      <td>-0.073535</td>\n",
              "      <td>0.017683</td>\n",
              "      <td>-0.033523</td>\n",
              "      <td>0.544341</td>\n",
              "      <td>0.221898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>0.129459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.152590</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.331357</td>\n",
              "      <td>0.221071</td>\n",
              "      <td>0.137337</td>\n",
              "      <td>0.263514</td>\n",
              "      <td>0.466581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>0.141282</td>\n",
              "      <td>0.152590</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>0.088933</td>\n",
              "      <td>0.281805</td>\n",
              "      <td>0.041265</td>\n",
              "      <td>0.239528</td>\n",
              "      <td>0.065068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>-0.081672</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>0.074752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>-0.073535</td>\n",
              "      <td>0.331357</td>\n",
              "      <td>0.088933</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197859</td>\n",
              "      <td>0.185071</td>\n",
              "      <td>-0.042163</td>\n",
              "      <td>0.130548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0.017683</td>\n",
              "      <td>0.221071</td>\n",
              "      <td>0.281805</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.197859</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140647</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.292695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>-0.033523</td>\n",
              "      <td>0.137337</td>\n",
              "      <td>0.041265</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>0.185071</td>\n",
              "      <td>0.140647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.033561</td>\n",
              "      <td>0.173844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.544341</td>\n",
              "      <td>0.263514</td>\n",
              "      <td>0.239528</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>-0.042163</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.033561</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.238356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>0.221898</td>\n",
              "      <td>0.466581</td>\n",
              "      <td>0.065068</td>\n",
              "      <td>0.074752</td>\n",
              "      <td>0.130548</td>\n",
              "      <td>0.292695</td>\n",
              "      <td>0.173844</td>\n",
              "      <td>0.238356</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0818dbd3-d102-48aa-a03b-101ca8933a0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0818dbd3-d102-48aa-a03b-101ca8933a0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0818dbd3-d102-48aa-a03b-101ca8933a0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Outcome', axis=1)"
      ],
      "metadata": {
        "id": "N_AYZhiqDkZi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Outcome']"
      ],
      "metadata": {
        "id": "Ezpx_gHLEXWe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mUbnIYWjD86U",
        "outputId": "b717067f-59ac-4f01-89c6-5ffd9f4a9b02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  \n",
              "0                       0.627   50  \n",
              "1                       0.351   31  \n",
              "2                       0.672   32  \n",
              "3                       0.167   21  \n",
              "4                       2.288   33  \n",
              "..                        ...  ...  \n",
              "763                     0.171   63  \n",
              "764                     0.340   27  \n",
              "765                     0.245   30  \n",
              "766                     0.349   47  \n",
              "767                     0.315   23  \n",
              "\n",
              "[768 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d9ce44d-cc18-42ad-8140-af7f9fd07dfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d9ce44d-cc18-42ad-8140-af7f9fd07dfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d9ce44d-cc18-42ad-8140-af7f9fd07dfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d9ce44d-cc18-42ad-8140-af7f9fd07dfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=48)"
      ],
      "metadata": {
        "id": "iBar9qn0EcNm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n"
      ],
      "metadata": {
        "id": "vEYDrOmSCqSL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "uQ-bLoDTDY1Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad, SGD"
      ],
      "metadata": {
        "id": "JWMdsTquDY6S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(8,activation='relu',input_dim=8))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  optimizer = hp.Choice('optimizer', values = ['RMSprop', 'Adam', 'Adagrad', 'SGD'])\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "LszpQBC_DY7i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuner object for KT class\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=5)"
      ],
      "metadata": {
        "id": "g69fCwfqDY8o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10,validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332ZSnl5DY93",
        "outputId": "10f0f6a3-1d38-490f-b298-80e187eedfe7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.7857142686843872\n",
            "\n",
            "Best val_accuracy So Far: 0.7857142686843872\n",
            "Total elapsed time: 00h 00m 08s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1COrTbFeDZA0",
        "outputId": "c7baa500-7701-42ae-9e2b-d30237a950a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'RMSprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "CFs2huSKCqUB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i12UKJMCIWWA",
        "outputId": "ff136bbe-e106-40bd-a0f0-5ea476e5427f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81\n",
            "Trainable params: 81\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will fit the best model now from the Initial_epoch as 11 as we already ran 10 previosly.\n",
        "best_model.fit(X_train, y_train, epochs=100, initial_epoch=11,validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBPZnOlVIWYW",
        "outputId": "3d90fc29-12e6-48cd-fcfb-7bb3470d2052"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 0.5393 - accuracy: 0.7622 - val_loss: 0.5179 - val_accuracy: 0.7727\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7541 - val_loss: 0.5091 - val_accuracy: 0.7662\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7557 - val_loss: 0.5012 - val_accuracy: 0.7597\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7590 - val_loss: 0.4941 - val_accuracy: 0.7662\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7606 - val_loss: 0.4881 - val_accuracy: 0.7597\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7638 - val_loss: 0.4834 - val_accuracy: 0.7727\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7671 - val_loss: 0.4800 - val_accuracy: 0.7792\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7687 - val_loss: 0.4762 - val_accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7752 - val_loss: 0.4742 - val_accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7769 - val_loss: 0.4722 - val_accuracy: 0.7792\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7769 - val_loss: 0.4713 - val_accuracy: 0.7792\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7785 - val_loss: 0.4699 - val_accuracy: 0.7792\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7785 - val_loss: 0.4691 - val_accuracy: 0.7792\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7834 - val_loss: 0.4685 - val_accuracy: 0.7792\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7801 - val_loss: 0.4680 - val_accuracy: 0.7727\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7834 - val_loss: 0.4674 - val_accuracy: 0.7727\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7801 - val_loss: 0.4673 - val_accuracy: 0.7727\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7785 - val_loss: 0.4669 - val_accuracy: 0.7727\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7834 - val_loss: 0.4666 - val_accuracy: 0.7792\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7850 - val_loss: 0.4669 - val_accuracy: 0.7792\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7801 - val_loss: 0.4672 - val_accuracy: 0.7792\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7785 - val_loss: 0.4677 - val_accuracy: 0.7857\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7785 - val_loss: 0.4680 - val_accuracy: 0.7857\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7818 - val_loss: 0.4685 - val_accuracy: 0.7857\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7818 - val_loss: 0.4684 - val_accuracy: 0.7857\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7801 - val_loss: 0.4683 - val_accuracy: 0.7857\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7818 - val_loss: 0.4684 - val_accuracy: 0.7857\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7818 - val_loss: 0.4681 - val_accuracy: 0.7857\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7834 - val_loss: 0.4681 - val_accuracy: 0.7857\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7850 - val_loss: 0.4682 - val_accuracy: 0.7857\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7818 - val_loss: 0.4691 - val_accuracy: 0.7857\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7818 - val_loss: 0.4694 - val_accuracy: 0.7857\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7834 - val_loss: 0.4695 - val_accuracy: 0.7857\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7818 - val_loss: 0.4702 - val_accuracy: 0.7857\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7834 - val_loss: 0.4706 - val_accuracy: 0.7792\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7834 - val_loss: 0.4714 - val_accuracy: 0.7857\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7818 - val_loss: 0.4714 - val_accuracy: 0.7857\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7850 - val_loss: 0.4720 - val_accuracy: 0.7857\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7785 - val_loss: 0.4725 - val_accuracy: 0.7857\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7834 - val_loss: 0.4730 - val_accuracy: 0.7857\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7834 - val_loss: 0.4730 - val_accuracy: 0.7857\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7818 - val_loss: 0.4736 - val_accuracy: 0.7857\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7866 - val_loss: 0.4739 - val_accuracy: 0.7857\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7850 - val_loss: 0.4744 - val_accuracy: 0.7857\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7866 - val_loss: 0.4746 - val_accuracy: 0.7857\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7866 - val_loss: 0.4752 - val_accuracy: 0.7922\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7866 - val_loss: 0.4753 - val_accuracy: 0.7922\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7850 - val_loss: 0.4755 - val_accuracy: 0.7922\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7883 - val_loss: 0.4754 - val_accuracy: 0.7922\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7883 - val_loss: 0.4755 - val_accuracy: 0.7922\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7866 - val_loss: 0.4758 - val_accuracy: 0.7922\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7850 - val_loss: 0.4765 - val_accuracy: 0.7922\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7850 - val_loss: 0.4770 - val_accuracy: 0.7922\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7932 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.4775 - val_accuracy: 0.7922\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4775 - val_accuracy: 0.7792\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7883 - val_loss: 0.4777 - val_accuracy: 0.7792\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7932 - val_loss: 0.4777 - val_accuracy: 0.7857\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7883 - val_loss: 0.4778 - val_accuracy: 0.7792\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4777 - val_accuracy: 0.7792\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7866 - val_loss: 0.4776 - val_accuracy: 0.7792\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7866 - val_loss: 0.4772 - val_accuracy: 0.7857\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7883 - val_loss: 0.4776 - val_accuracy: 0.7857\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7850 - val_loss: 0.4774 - val_accuracy: 0.7792\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7866 - val_loss: 0.4775 - val_accuracy: 0.7857\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7883 - val_loss: 0.4776 - val_accuracy: 0.7857\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7866 - val_loss: 0.4778 - val_accuracy: 0.7857\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7883 - val_loss: 0.4777 - val_accuracy: 0.7857\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7883 - val_loss: 0.4778 - val_accuracy: 0.7857\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7866 - val_loss: 0.4777 - val_accuracy: 0.7857\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4779 - val_accuracy: 0.7857\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7866 - val_loss: 0.4783 - val_accuracy: 0.7792\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7883 - val_loss: 0.4779 - val_accuracy: 0.7857\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7866 - val_loss: 0.4780 - val_accuracy: 0.7857\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7915 - val_loss: 0.4777 - val_accuracy: 0.7857\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7866 - val_loss: 0.4777 - val_accuracy: 0.7857\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7883 - val_loss: 0.4778 - val_accuracy: 0.7857\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7883 - val_loss: 0.4782 - val_accuracy: 0.7857\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7883 - val_loss: 0.4788 - val_accuracy: 0.7792\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7866 - val_loss: 0.4788 - val_accuracy: 0.7792\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7883 - val_loss: 0.4794 - val_accuracy: 0.7792\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4794 - val_accuracy: 0.7792\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7866 - val_loss: 0.4794 - val_accuracy: 0.7727\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7883 - val_loss: 0.4797 - val_accuracy: 0.7792\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7932 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7964 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7948 - val_loss: 0.4796 - val_accuracy: 0.7727\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7932 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7932 - val_loss: 0.4793 - val_accuracy: 0.7662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb957c421d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting No. of Nodes in a layer\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  units = hp.Int('units', min_value=4,max_value=96,step=4)\n",
        "\n",
        "  model.add(Dense(units=units, activation='relu',input_dim=8))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='Adam',metrics=['accuracy'], loss='binary_crossentropy')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "X0eM-hvMIWZx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=5,\n",
        "                        project_name = 'keras-tuner'\n",
        "                        )"
      ],
      "metadata": {
        "id": "aKcNzpYwIWcR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMv_36mrIWfp",
        "outputId": "03d81f6c-291d-4eea-aef7-e7db5c8fdec0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.7922077775001526\n",
            "\n",
            "Best val_accuracy So Far: 0.798701286315918\n",
            "Total elapsed time: 00h 00m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2KfrJetCqWZ",
        "outputId": "87beccdc-8359-487a-d212-a838181ee7e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "29P3WLguCqYP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(X_train, y_train, epochs=100, initial_epoch=11, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxUgK74yjRO_",
        "outputId": "82c74358-2cf6-4239-f7be-285e3be96fb0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100\n",
            "20/20 [==============================] - 1s 20ms/step - loss: 0.4884 - accuracy: 0.7736 - val_loss: 0.4816 - val_accuracy: 0.8052\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7736 - val_loss: 0.4775 - val_accuracy: 0.8052\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7736 - val_loss: 0.4736 - val_accuracy: 0.7987\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.7850 - val_loss: 0.4711 - val_accuracy: 0.7857\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4682 - accuracy: 0.7883 - val_loss: 0.4689 - val_accuracy: 0.8117\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4653 - accuracy: 0.7834 - val_loss: 0.4678 - val_accuracy: 0.8117\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4627 - accuracy: 0.7866 - val_loss: 0.4662 - val_accuracy: 0.8117\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7834 - val_loss: 0.4657 - val_accuracy: 0.8117\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7818 - val_loss: 0.4653 - val_accuracy: 0.8117\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7915 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7834 - val_loss: 0.4652 - val_accuracy: 0.7857\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7850 - val_loss: 0.4654 - val_accuracy: 0.7727\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4530 - accuracy: 0.7883 - val_loss: 0.4643 - val_accuracy: 0.7857\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7850 - val_loss: 0.4657 - val_accuracy: 0.7857\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.7818 - val_loss: 0.4656 - val_accuracy: 0.7857\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4497 - accuracy: 0.7866 - val_loss: 0.4654 - val_accuracy: 0.7857\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7866 - val_loss: 0.4657 - val_accuracy: 0.7857\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7915 - val_loss: 0.4660 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7866 - val_loss: 0.4666 - val_accuracy: 0.7857\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7866 - val_loss: 0.4669 - val_accuracy: 0.7857\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.7883 - val_loss: 0.4671 - val_accuracy: 0.7792\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.7883 - val_loss: 0.4667 - val_accuracy: 0.7792\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7834 - val_loss: 0.4672 - val_accuracy: 0.7792\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7883 - val_loss: 0.4673 - val_accuracy: 0.7727\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4680 - val_accuracy: 0.7727\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4680 - val_accuracy: 0.7792\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4687 - val_accuracy: 0.7792\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4691 - val_accuracy: 0.7792\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.7850 - val_loss: 0.4698 - val_accuracy: 0.7792\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4368 - accuracy: 0.7883 - val_loss: 0.4689 - val_accuracy: 0.7792\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4363 - accuracy: 0.7866 - val_loss: 0.4695 - val_accuracy: 0.7792\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7866 - val_loss: 0.4692 - val_accuracy: 0.7792\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4350 - accuracy: 0.7850 - val_loss: 0.4703 - val_accuracy: 0.7792\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7850 - val_loss: 0.4702 - val_accuracy: 0.7727\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7818 - val_loss: 0.4686 - val_accuracy: 0.7792\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7850 - val_loss: 0.4679 - val_accuracy: 0.7792\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4321 - accuracy: 0.7834 - val_loss: 0.4684 - val_accuracy: 0.7792\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4311 - accuracy: 0.7818 - val_loss: 0.4694 - val_accuracy: 0.7792\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.7850 - val_loss: 0.4682 - val_accuracy: 0.7792\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7834 - val_loss: 0.4693 - val_accuracy: 0.7792\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7801 - val_loss: 0.4696 - val_accuracy: 0.7792\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7818 - val_loss: 0.4683 - val_accuracy: 0.7792\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4292 - accuracy: 0.7883 - val_loss: 0.4696 - val_accuracy: 0.7792\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7866 - val_loss: 0.4694 - val_accuracy: 0.7792\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7883 - val_loss: 0.4710 - val_accuracy: 0.7792\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7883 - val_loss: 0.4715 - val_accuracy: 0.7792\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7883 - val_loss: 0.4708 - val_accuracy: 0.7792\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.7883 - val_loss: 0.4701 - val_accuracy: 0.7792\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.4695 - val_accuracy: 0.7792\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4707 - val_accuracy: 0.7792\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7915 - val_loss: 0.4689 - val_accuracy: 0.7792\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7915 - val_loss: 0.4679 - val_accuracy: 0.7792\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4690 - val_accuracy: 0.7792\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4231 - accuracy: 0.7915 - val_loss: 0.4700 - val_accuracy: 0.7792\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.4698 - val_accuracy: 0.7792\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7964 - val_loss: 0.4712 - val_accuracy: 0.7792\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7932 - val_loss: 0.4716 - val_accuracy: 0.7792\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7932 - val_loss: 0.4713 - val_accuracy: 0.7792\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7948 - val_loss: 0.4728 - val_accuracy: 0.7792\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.7980 - val_loss: 0.4726 - val_accuracy: 0.7727\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8062 - val_loss: 0.4714 - val_accuracy: 0.7792\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7997 - val_loss: 0.4719 - val_accuracy: 0.7792\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4188 - accuracy: 0.8029 - val_loss: 0.4716 - val_accuracy: 0.7857\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.7997 - val_loss: 0.4738 - val_accuracy: 0.7792\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7997 - val_loss: 0.4723 - val_accuracy: 0.7857\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7980 - val_loss: 0.4736 - val_accuracy: 0.7857\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4173 - accuracy: 0.7964 - val_loss: 0.4733 - val_accuracy: 0.7857\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4168 - accuracy: 0.7997 - val_loss: 0.4744 - val_accuracy: 0.7792\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4163 - accuracy: 0.8046 - val_loss: 0.4744 - val_accuracy: 0.7792\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4162 - accuracy: 0.8062 - val_loss: 0.4753 - val_accuracy: 0.7792\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8062 - val_loss: 0.4749 - val_accuracy: 0.7792\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8062 - val_loss: 0.4759 - val_accuracy: 0.7727\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.7964 - val_loss: 0.4743 - val_accuracy: 0.7727\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.8013 - val_loss: 0.4757 - val_accuracy: 0.7792\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8029 - val_loss: 0.4735 - val_accuracy: 0.7727\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4139 - accuracy: 0.8046 - val_loss: 0.4732 - val_accuracy: 0.7727\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4130 - accuracy: 0.8046 - val_loss: 0.4751 - val_accuracy: 0.7727\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8046 - val_loss: 0.4752 - val_accuracy: 0.7662\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8062 - val_loss: 0.4732 - val_accuracy: 0.7662\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.7997 - val_loss: 0.4732 - val_accuracy: 0.7662\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8094 - val_loss: 0.4762 - val_accuracy: 0.7597\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8111 - val_loss: 0.4758 - val_accuracy: 0.7662\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8094 - val_loss: 0.4761 - val_accuracy: 0.7662\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4110 - accuracy: 0.8094 - val_loss: 0.4788 - val_accuracy: 0.7662\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8111 - val_loss: 0.4778 - val_accuracy: 0.7662\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8111 - val_loss: 0.4762 - val_accuracy: 0.7597\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8078 - val_loss: 0.4753 - val_accuracy: 0.7792\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8078 - val_loss: 0.4752 - val_accuracy: 0.7662\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8127 - val_loss: 0.4772 - val_accuracy: 0.7792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb958d93750>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For selecting no of Layers, no. of Nodes, Optimizes and Activation function\n",
        "def build_model(hp):\n",
        "\n",
        "   model = Sequential()\n",
        "\n",
        "   count =0\n",
        "\n",
        "   for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
        "\n",
        "     if count == 0:\n",
        "       model.add(Dense(hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n",
        "                       activation = hp.Choice('activation' + str(i), values=['sigmoid','relu','tanh','elu']),\n",
        "                       input_dim=8\n",
        "                       )\n",
        "       )\n",
        "     else:\n",
        "\n",
        "       model.add(Dense(hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n",
        "                       activation = hp.Choice('activation' + str(i), values=['sigmoid','relu','tanh','elu']),\n",
        "                       )\n",
        "       )\n",
        "       count+=1\n",
        "\n",
        "   model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "   model.compile(optimizer=hp.Choice('optimizer', values=['rmsprop','adam','adagrad','adadelta','sgd']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "   return model\n"
      ],
      "metadata": {
        "id": "hi1D7Gi1jRRw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=8,\n",
        "                        directory = 'Tuner',\n",
        "                        project_name='Final_Tuning')"
      ],
      "metadata": {
        "id": "LqMsdMVojx_P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7UB3nqTjyBs",
        "outputId": "77365a8f-7081-4a3b-e83e-f0bd558da682"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.7077922224998474\n",
            "\n",
            "Best val_accuracy So Far: 0.7922077775001526\n",
            "Total elapsed time: 00h 00m 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using 10 epochs\n",
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUAIbAzvBIxh",
        "outputId": "e33eb075-4db0-4ced-a626-ecf5c26f12a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 1, 'units0': 120, 'activation0': 'elu', 'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "yINYa36ejyIR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(X_train, y_train, epochs=100, initial_epoch=11, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5LSWjXbjRTo",
        "outputId": "609cfcc4-10b1-4301-d87e-0a470f8caea1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100\n",
            "20/20 [==============================] - 1s 10ms/step - loss: 0.4884 - accuracy: 0.7622 - val_loss: 0.4776 - val_accuracy: 0.7857\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7638 - val_loss: 0.4739 - val_accuracy: 0.7857\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7655 - val_loss: 0.4707 - val_accuracy: 0.7857\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7687 - val_loss: 0.4712 - val_accuracy: 0.7922\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7655 - val_loss: 0.4729 - val_accuracy: 0.7857\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7671 - val_loss: 0.4715 - val_accuracy: 0.7857\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7655 - val_loss: 0.4750 - val_accuracy: 0.7857\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7704 - val_loss: 0.4735 - val_accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7655 - val_loss: 0.4705 - val_accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7687 - val_loss: 0.4726 - val_accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7720 - val_loss: 0.4755 - val_accuracy: 0.7857\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7671 - val_loss: 0.4760 - val_accuracy: 0.7857\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7769 - val_loss: 0.4735 - val_accuracy: 0.7857\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7769 - val_loss: 0.4756 - val_accuracy: 0.7857\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7638 - val_loss: 0.4761 - val_accuracy: 0.7792\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7687 - val_loss: 0.4729 - val_accuracy: 0.7792\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7720 - val_loss: 0.4723 - val_accuracy: 0.7857\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7785 - val_loss: 0.4708 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7752 - val_loss: 0.4689 - val_accuracy: 0.7857\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7769 - val_loss: 0.4741 - val_accuracy: 0.7857\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7785 - val_loss: 0.4693 - val_accuracy: 0.7857\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7785 - val_loss: 0.4695 - val_accuracy: 0.7857\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7801 - val_loss: 0.4698 - val_accuracy: 0.7792\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7785 - val_loss: 0.4685 - val_accuracy: 0.7857\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7752 - val_loss: 0.4713 - val_accuracy: 0.7857\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7801 - val_loss: 0.4706 - val_accuracy: 0.7857\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7818 - val_loss: 0.4702 - val_accuracy: 0.7857\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7785 - val_loss: 0.4708 - val_accuracy: 0.7857\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7687 - val_loss: 0.4705 - val_accuracy: 0.7857\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7785 - val_loss: 0.4732 - val_accuracy: 0.7857\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7704 - val_loss: 0.4779 - val_accuracy: 0.7727\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7720 - val_loss: 0.4755 - val_accuracy: 0.7857\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7769 - val_loss: 0.4774 - val_accuracy: 0.7792\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7720 - val_loss: 0.4747 - val_accuracy: 0.7727\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7736 - val_loss: 0.4735 - val_accuracy: 0.7792\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7818 - val_loss: 0.4733 - val_accuracy: 0.7727\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7752 - val_loss: 0.4717 - val_accuracy: 0.7792\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7769 - val_loss: 0.4700 - val_accuracy: 0.7857\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7769 - val_loss: 0.4697 - val_accuracy: 0.7792\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7801 - val_loss: 0.4705 - val_accuracy: 0.7792\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7736 - val_loss: 0.4713 - val_accuracy: 0.7792\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7850 - val_loss: 0.4722 - val_accuracy: 0.7792\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7834 - val_loss: 0.4743 - val_accuracy: 0.7792\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7850 - val_loss: 0.4803 - val_accuracy: 0.7662\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7769 - val_loss: 0.4743 - val_accuracy: 0.7727\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7850 - val_loss: 0.4710 - val_accuracy: 0.7727\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7850 - val_loss: 0.4725 - val_accuracy: 0.7727\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7850 - val_loss: 0.4692 - val_accuracy: 0.7792\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7883 - val_loss: 0.4714 - val_accuracy: 0.7727\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7752 - val_loss: 0.4714 - val_accuracy: 0.7727\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7834 - val_loss: 0.4704 - val_accuracy: 0.7727\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7752 - val_loss: 0.4746 - val_accuracy: 0.7792\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7769 - val_loss: 0.4745 - val_accuracy: 0.7727\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7752 - val_loss: 0.4734 - val_accuracy: 0.7792\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7801 - val_loss: 0.4720 - val_accuracy: 0.7727\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7818 - val_loss: 0.4726 - val_accuracy: 0.7792\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7818 - val_loss: 0.4744 - val_accuracy: 0.7727\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7834 - val_loss: 0.4758 - val_accuracy: 0.7792\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7801 - val_loss: 0.4709 - val_accuracy: 0.7727\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7818 - val_loss: 0.4733 - val_accuracy: 0.7792\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7801 - val_loss: 0.4753 - val_accuracy: 0.7662\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7834 - val_loss: 0.4797 - val_accuracy: 0.7792\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7883 - val_loss: 0.4767 - val_accuracy: 0.7597\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7866 - val_loss: 0.4752 - val_accuracy: 0.7727\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7932 - val_loss: 0.4730 - val_accuracy: 0.7727\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7866 - val_loss: 0.4760 - val_accuracy: 0.7662\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7866 - val_loss: 0.4759 - val_accuracy: 0.7792\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7883 - val_loss: 0.4735 - val_accuracy: 0.7727\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4707 - val_accuracy: 0.7727\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7964 - val_loss: 0.4718 - val_accuracy: 0.7792\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7834 - val_loss: 0.4719 - val_accuracy: 0.7727\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7883 - val_loss: 0.4704 - val_accuracy: 0.7727\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7915 - val_loss: 0.4761 - val_accuracy: 0.7662\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7818 - val_loss: 0.4756 - val_accuracy: 0.7662\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7866 - val_loss: 0.4737 - val_accuracy: 0.7792\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7866 - val_loss: 0.4764 - val_accuracy: 0.7792\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7866 - val_loss: 0.4735 - val_accuracy: 0.7857\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7948 - val_loss: 0.4760 - val_accuracy: 0.7792\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7980 - val_loss: 0.4735 - val_accuracy: 0.7727\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7932 - val_loss: 0.4803 - val_accuracy: 0.7662\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4732 - val_accuracy: 0.7857\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7818 - val_loss: 0.4707 - val_accuracy: 0.7857\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7883 - val_loss: 0.4764 - val_accuracy: 0.7597\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7932 - val_loss: 0.4769 - val_accuracy: 0.7727\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7883 - val_loss: 0.4777 - val_accuracy: 0.7727\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7866 - val_loss: 0.4713 - val_accuracy: 0.7727\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7948 - val_loss: 0.4722 - val_accuracy: 0.7662\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7948 - val_loss: 0.4735 - val_accuracy: 0.7792\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7997 - val_loss: 0.4713 - val_accuracy: 0.7792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb954661a10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuner.get_best_hyperparameters()[0].values)"
      ],
      "metadata": {
        "id": "CLnQSvJ2jRWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c66a14e-9708-4a52-b484-aec2bf42382a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_layers': 1, 'units0': 120, 'activation0': 'elu', 'optimizer': 'adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "4fCebDkXBzly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e4d572-4d88-4023-a1d5-d4d3bd9f57af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 20\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': None}\n",
            "units0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation0 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam', 'adagrad', 'adadelta', 'sgd'], 'ordered': False}\n",
            "units1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation1 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation2 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation3 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation4 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation5 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation6 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units7 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation7 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n",
            "units8 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}\n",
            "activation8 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh', 'elu'], 'ordered': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "sh1qcrPtBzns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70624b9e-f508-4843-bec4-63bdeba00c31"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Tuner/Final_Tuning\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fb95835f190>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units0: 120\n",
            "activation0: elu\n",
            "optimizer: adam\n",
            "Score: 0.7922077775001526\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units0: 96\n",
            "activation0: sigmoid\n",
            "optimizer: rmsprop\n",
            "units1: 24\n",
            "activation1: relu\n",
            "units2: 24\n",
            "activation2: relu\n",
            "units3: 56\n",
            "activation3: tanh\n",
            "units4: 128\n",
            "activation4: relu\n",
            "units5: 80\n",
            "activation5: elu\n",
            "units6: 128\n",
            "activation6: relu\n",
            "units7: 40\n",
            "activation7: elu\n",
            "units8: 48\n",
            "activation8: tanh\n",
            "Score: 0.7662337422370911\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 9\n",
            "units0: 120\n",
            "activation0: relu\n",
            "optimizer: adagrad\n",
            "units1: 32\n",
            "activation1: tanh\n",
            "units2: 96\n",
            "activation2: tanh\n",
            "units3: 72\n",
            "activation3: relu\n",
            "units4: 16\n",
            "activation4: tanh\n",
            "units5: 120\n",
            "activation5: relu\n",
            "units6: 48\n",
            "activation6: tanh\n",
            "units7: 104\n",
            "activation7: relu\n",
            "units8: 72\n",
            "activation8: relu\n",
            "Score: 0.7077922224998474\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units0: 24\n",
            "activation0: relu\n",
            "optimizer: adam\n",
            "units1: 8\n",
            "activation1: sigmoid\n",
            "units2: 8\n",
            "activation2: sigmoid\n",
            "units3: 8\n",
            "activation3: sigmoid\n",
            "Score: 0.6818181872367859\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 9\n",
            "units0: 32\n",
            "activation0: sigmoid\n",
            "optimizer: adam\n",
            "units1: 56\n",
            "activation1: sigmoid\n",
            "units2: 80\n",
            "activation2: elu\n",
            "units3: 96\n",
            "activation3: tanh\n",
            "units4: 8\n",
            "activation4: sigmoid\n",
            "units5: 8\n",
            "activation5: sigmoid\n",
            "units6: 8\n",
            "activation6: sigmoid\n",
            "units7: 8\n",
            "activation7: sigmoid\n",
            "units8: 8\n",
            "activation8: sigmoid\n",
            "Score: 0.6818181872367859\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units0: 88\n",
            "activation0: sigmoid\n",
            "optimizer: adagrad\n",
            "units1: 120\n",
            "activation1: elu\n",
            "units2: 104\n",
            "activation2: sigmoid\n",
            "units3: 96\n",
            "activation3: relu\n",
            "units4: 72\n",
            "activation4: tanh\n",
            "units5: 32\n",
            "activation5: sigmoid\n",
            "units6: 72\n",
            "activation6: tanh\n",
            "units7: 8\n",
            "activation7: elu\n",
            "units8: 56\n",
            "activation8: elu\n",
            "Score: 0.6818181872367859\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units0: 64\n",
            "activation0: relu\n",
            "optimizer: adagrad\n",
            "units1: 24\n",
            "activation1: elu\n",
            "units2: 16\n",
            "activation2: sigmoid\n",
            "units3: 72\n",
            "activation3: sigmoid\n",
            "units4: 104\n",
            "activation4: elu\n",
            "units5: 24\n",
            "activation5: tanh\n",
            "units6: 40\n",
            "activation6: relu\n",
            "units7: 80\n",
            "activation7: elu\n",
            "units8: 72\n",
            "activation8: relu\n",
            "Score: 0.6688311696052551\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units0: 56\n",
            "activation0: tanh\n",
            "optimizer: adagrad\n",
            "units1: 72\n",
            "activation1: elu\n",
            "units2: 112\n",
            "activation2: elu\n",
            "units3: 24\n",
            "activation3: sigmoid\n",
            "units4: 112\n",
            "activation4: elu\n",
            "units5: 24\n",
            "activation5: relu\n",
            "units6: 16\n",
            "activation6: sigmoid\n",
            "units7: 64\n",
            "activation7: relu\n",
            "units8: 64\n",
            "activation8: relu\n",
            "Score: 0.3181818127632141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZDdVcl8Bzp2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1GMIqRyBztc"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}